import streamlit as st
import pdfplumber
import docx2txt
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd
from datetime import datetime
import sqlite3
import tempfile
import os

# Download required NLTK data
nltk.download('punkt')
nltk.download('stopwords')

class ResumeAnalyzer:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.skill_keywords = self._load_skill_keywords()
        
    def _load_skill_keywords(self):
        # This would typically come from a comprehensive skills database
        common_skills = [
            'python', 'java', 'javascript', 'sql', 'html', 'css', 'machine learning', 
            'deep learning', 'data analysis', 'tableau', 'power bi', 'excel', 
            'project management', 'agile', 'scrum', 'devops', 'aws', 'azure', 
            'google cloud', 'docker', 'kubernetes', 'react', 'angular', 'vue', 
            'node.js', 'django', 'flask', 'fastapi', 'tensorflow', 'pytorch', 
            'natural language processing', 'computer vision', 'ci/cd', 'git', 
            'jenkins', 'rest api', 'graphql', 'mongodb', 'postgresql', 'mysql'
        ]
        return set(common_skills)
    
    def extract_text_from_file(self, file):
        """Extract text from PDF or DOCX files"""
        text = ""
        if file.type == "application/pdf":
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() + "\n"
        elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            text = docx2txt.process(file)
        else:
            raise ValueError("Unsupported file format")
        return text
    
    def preprocess_text(self, text):
        """Clean and preprocess text"""
        # Convert to lowercase
        text = text.lower()
        # Remove special characters and digits
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        # Tokenize
        tokens = word_tokenize(text)
        # Remove stopwords and short tokens
        tokens = [token for token in tokens if token not in self.stop_words and len(token) > 2]
        return " ".join(tokens)
    
    def extract_skills(self, text):
        """Extract skills from text"""
        found_skills = []
        for skill in self.skill_keywords:
            if skill in text.lower():
                found_skills.append(skill)
        return found_skills
    
    def extract_education(self, text):
        """Extract education information"""
        education_keywords = ['bachelor', 'master', 'phd', 'degree', 'diploma', 'certificate', 'bs', 'ms', 'mba']
        sentences = re.split(r'[.!?]', text)
        education_sentences = []
        for sentence in sentences:
            if any(word in sentence.lower() for word in education_keywords):
                education_sentences.append(sentence.strip())
        return education_sentences
    
    def calculate_hard_match_score(self, resume_text, jd_text):
        """Calculate hard match score based on keyword matching"""
        resume_tokens = set(self.preprocess_text(resume_text).split())
        jd_tokens = set(self.preprocess_text(jd_text).split())
        
        if not jd_tokens:
            return 0
            
        intersection = resume_tokens.intersection(jd_tokens)
        return len(intersection) / len(jd_tokens) * 100
    
    def calculate_semantic_similarity(self, resume_text, jd_text):
        """Calculate semantic similarity using TF-IDF and cosine similarity"""
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform([resume_text, jd_text])
        cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])
        return cosine_sim[0][0] * 100
    
    def calculate_final_score(self, hard_score, semantic_score, hard_weight=0.6, semantic_weight=0.4):
        """Calculate weighted final score"""
        return (hard_score * hard_weight) + (semantic_score * semantic_weight)
    
    def get_missing_elements(self, resume_text, jd_text):
        """Identify missing skills/qualifications from JD"""
        jd_skills = self.extract_skills(jd_text)
        resume_skills = self.extract_skills(resume_text)
        missing_skills = [skill for skill in jd_skills if skill not in resume_skills]
        
        # Extract education requirements from JD
        jd_education = self.extract_education(jd_text)
        resume_education = self.extract_education(resume_text)
        missing_education = []
        
        # Simple check for education gaps
        if jd_education and not resume_education:
            missing_education = jd_education
            
        return missing_skills, missing_education
    
    def get_verdict(self, score):
        """Get suitability verdict based on score"""
        if score >= 75:
            return "High suitability"
        elif score >= 50:
            return "Medium suitability"
        else:
            return "Low suitability"
    
    def generate_feedback(self, missing_skills, missing_education, score):
        """Generate personalized feedback for improvement"""
        feedback = []
        
        if score < 50:
            feedback.append("Your resume needs significant improvements to match job requirements.")
        elif score < 75:
            feedback.append("Your resume has some alignment but could be improved.")
        else:
            feedback.append("Your resume is well-aligned with the job requirements.")
        
        if missing_skills:
            feedback.append(f"Consider adding these skills: {', '.join(missing_skills)}")
        
        if missing_education:
            feedback.append(f"Consider highlighting these qualifications: {', '.join(missing_education)}")
        
        if not feedback:
            feedback.append("Your resume looks good! Keep up the good work.")
            
        return feedback

class DatabaseManager:
    def __init__(self, db_name="resume_evaluations.db"):
        self.db_name = db_name
        self.init_db()
    
    def init_db(self):
        """Initialize database with required tables"""
        conn = sqlite3.connect(self.db_name)
        c = conn.cursor()
        
        # Create evaluations table
        c.execute('''CREATE TABLE IF NOT EXISTS evaluations
                     (id INTEGER PRIMARY KEY AUTOINCREMENT,
                      student_name TEXT,
                      job_title TEXT,
                      hard_score REAL,
                      semantic_score REAL,
                      final_score REAL,
                      verdict TEXT,
                      missing_skills TEXT,
                      missing_education TEXT,
                      feedback TEXT,
                      evaluation_date TIMESTAMP)''')
        
        # Create jobs table
        c.execute('''CREATE TABLE IF NOT EXISTS jobs
                     (id INTEGER PRIMARY KEY AUTOINCREMENT,
                      job_title TEXT,
                      job_description TEXT,
                      upload_date TIMESTAMP)''')
        
        conn.commit()
        conn.close()
    
    def save_evaluation(self, evaluation_data):
        """Save evaluation results to database"""
        conn = sqlite3.connect(self.db_name)
        c = conn.cursor()
        
        c.execute('''INSERT INTO evaluations 
                     (student_name, job_title, hard_score, semantic_score, final_score, 
                      verdict, missing_skills, missing_education, feedback, evaluation_date)
                     VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                 (evaluation_data['student_name'],
                  evaluation_data['job_title'],
                  evaluation_data['hard_score'],
                  evaluation_data['semantic_score'],
                  evaluation_data['final_score'],
                  evaluation_data['verdict'],
                  ', '.join(evaluation_data['missing_skills']),
                  ', '.join(evaluation_data['missing_education']),
                  ' | '.join(evaluation_data['feedback']),
                  datetime.now()))
        
        conn.commit()
        conn.close()
    
    def save_job(self, job_title, job_description):
        """Save job description to database"""
        conn = sqlite3.connect(self.db_name)
        c = conn.cursor()
        
        c.execute('''INSERT INTO jobs (job_title, job_description, upload_date)
                     VALUES (?, ?, ?)''',
                 (job_title, job_description, datetime.now()))
        
        conn.commit()
        conn.close()
    
    def get_evaluations(self):
        """Retrieve all evaluations from database"""
        conn = sqlite3.connect(self.db_name)
        c = conn.cursor()
        
        c.execute('''SELECT * FROM evaluations ORDER BY evaluation_date DESC''')
        evaluations = c.fetchall()
        
        conn.close()
        return evaluations
    
    def get_jobs(self):
        """Retrieve all jobs from database"""
        conn = sqlite3.connect(self.db_name)
        c = conn.cursor()
        
        c.execute('''SELECT * FROM jobs ORDER BY upload_date DESC''')
        jobs = c.fetchall()
        
        conn.close()
        return jobs

def main():
    st.set_page_config(page_title="Resume Relevance Check System", layout="wide")
    st.title("Automated Resume Relevance Check System")
    
    analyzer = ResumeAnalyzer()
    db_manager = DatabaseManager()
    
    # Sidebar for navigation
    menu = st.sidebar.selectbox("Menu", ["Home", "Upload Job", "Evaluate Resume", "View Results", "Dashboard"])
    
    if menu == "Home":
        st.header("Welcome to the Resume Relevance Check System")
        st.write("""
        This system helps automate resume evaluation against job requirements:
        - Upload job descriptions
        - Evaluate resumes against job requirements
        - Get relevance scores and improvement feedback
        - View results in the dashboard
        """)
        
        st.subheader("How to Use")
        st.write("1. Go to 'Upload Job' to add a new job description")
        st.write("2. Go to 'Evaluate Resume' to analyze a resume against a job")
        st.write("3. View all results in 'View Results' or 'Dashboard'")
    
    elif menu == "Upload Job":
        st.header("Upload Job Description")
        job_title = st.text_input("Job Title")
        job_description = st.text_area("Job Description", height=300)
        
        if st.button("Save Job"):
            if job_title and job_description:
                db_manager.save_job(job_title, job_description)
                st.success("Job description saved successfully!")
            else:
                st.error("Please provide both job title and description")
    
    elif menu == "Evaluate Resume":
        st.header("Evaluate Resume Against Job")
        
        # Get available jobs
        jobs = db_manager.get_jobs()
        job_options = {f"{job[1]} (ID: {job[0]})": job[2] for job in jobs}
        
        if not job_options:
            st.warning("No jobs available. Please upload a job description first.")
            return
        
        selected_job_label = st.selectbox("Select Job", list(job_options.keys()))
        jd_text = job_options[selected_job_label]
        
        student_name = st.text_input("Student Name")
        resume_file = st.file_uploader("Upload Resume", type=["pdf", "docx"])
        
        if st.button("Evaluate Resume") and resume_file and student_name:
            with st.spinner("Analyzing resume..."):
                # Extract text from resume
                resume_text = analyzer.extract_text_from_file(resume_file)
                
                # Calculate scores
                hard_score = analyzer.calculate_hard_match_score(resume_text, jd_text)
                semantic_score = analyzer.calculate_semantic_similarity(resume_text, jd_text)
                final_score = analyzer.calculate_final_score(hard_score, semantic_score)
                
                # Get missing elements
                missing_skills, missing_education = analyzer.get_missing_elements(resume_text, jd_text)
                
                # Get verdict and feedback
                verdict = analyzer.get_verdict(final_score)
                feedback = analyzer.generate_feedback(missing_skills, missing_education, final_score)
                
                # Save evaluation
                evaluation_data = {
                    'student_name': student_name,
                    'job_title': selected_job_label.split(" (ID:")[0],
                    'hard_score': hard_score,
                    'semantic_score': semantic_score,
                    'final_score': final_score,
                    'verdict': verdict,
                    'missing_skills': missing_skills,
                    'missing_education': missing_education,
                    'feedback': feedback
                }
                db_manager.save_evaluation(evaluation_data)
                
                # Display results
                st.subheader("Evaluation Results")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Hard Match Score", f"{hard_score:.2f}%")
                with col2:
                    st.metric("Semantic Score", f"{semantic_score:.2f}%")
                with col3:
                    st.metric("Final Score", f"{final_score:.2f}%", verdict)
                
                st.subheader("Verdict")
                st.write(verdict)
                
                if missing_skills:
                    st.subheader("Missing Skills")
                    st.write(", ".join(missing_skills))
                
                if missing_education:
                    st.subheader("Missing Education/Qualifications")
                    st.write(", ".join(missing_education))
                
                st.subheader("Improvement Feedback")
                for item in feedback:
                    st.write(f"- {item}")
    
    elif menu == "View Results":
        st.header("Evaluation Results")
        evaluations = db_manager.get_evaluations()
        
        if not evaluations:
            st.info("No evaluations found.")
            return
        
        # Convert to DataFrame for better display
        eval_df = pd.DataFrame(evaluations, columns=[
            'ID', 'Student Name', 'Job Title', 'Hard Score', 'Semantic Score', 
            'Final Score', 'Verdict', 'Missing Skills', 'Missing Education', 
            'Feedback', 'Evaluation Date'
        ])
        
        # Filter options
        job_filter = st.multiselect(
            "Filter by Job Title",
            options=eval_df['Job Title'].unique()
        )
        
        verdict_filter = st.multiselect(
            "Filter by Verdict",
            options=eval_df['Verdict'].unique()
        )
        
        # Apply filters
        filtered_df = eval_df
        if job_filter:
            filtered_df = filtered_df[filtered_df['Job Title'].isin(job_filter)]
        if verdict_filter:
            filtered_df = filtered_df[filtered_df['Verdict'].isin(verdict_filter)]
        
        st.dataframe(filtered_df)
        
        # Option to download results
        csv = filtered_df.to_csv(index=False)
        st.download_button(
            label="Download Results as CSV",
            data=csv,
            file_name="resume_evaluations.csv",
            mime="text/csv"
        )
    
    elif menu == "Dashboard":
        st.header("Analytics Dashboard")
        evaluations = db_manager.get_evaluations()
        
        if not evaluations:
            st.info("No evaluations found for analytics.")
            return
        
        eval_df = pd.DataFrame(evaluations, columns=[
            'ID', 'Student Name', 'Job Title', 'Hard Score', 'Semantic Score', 
            'Final Score', 'Verdict', 'Missing Skills', 'Missing Education', 
            'Feedback', 'Evaluation Date'
        ])
        
        # Overall statistics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Evaluations", len(eval_df))
        with col2:
            avg_score = eval_df['Final Score'].mean()
            st.metric("Average Score", f"{avg_score:.2f}%")
        with col3:
            high_suitability = len(eval_df[eval_df['Verdict'] == 'High suitability'])
            st.metric("High Suitability", high_suitability)
        
        # Score distribution
        st.subheader("Score Distribution")
        st.bar_chart(eval_df['Final Score'])
        
        # Verdict distribution
        st.subheader("Verdict Distribution")
        verdict_counts = eval_df['Verdict'].value_counts()
        st.plotly_chart(px.pie(
            values=verdict_counts.values,
            names=verdict_counts.index,
            title="Distribution of Verdicts"
        ), use_container_width=True)
        
        # Trends over time
        st.subheader("Trends Over Time")
        eval_df['Evaluation Date'] = pd.to_datetime(eval_df['Evaluation Date'])
        eval_df['Date'] = eval_df['Evaluation Date'].dt.date
        daily_avg = eval_df.groupby('Date')['Final Score'].mean().reset_index()
        st.line_chart(daily_avg.set_index('Date'))

if __name__ == "__main__":
    main()
